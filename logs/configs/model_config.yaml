accumulate: 2
attention_head_size: 4
batch_size: 64
data_path: data/merged/full_merged.csv
dropout: 0.2
early_stop_patience: 5
grad_clip: 0.2
hidden_size: 128
learning_rate: 0.00759
log_name: tft_multi
loss_schedule:
  0:
  - 6.0
  - 3.0
  - 4.0
  - 1.5
  - 3.5
  - 2.5
  - 1.5
  - 1.2
  - 1.2
  - 1.8
  - 1.3
  5:
  - 5.0
  - 3.0
  - 3.5
  - 1.5
  - 3.0
  - 2.0
  - 1.5
  - 1.0
  - 1.0
  - 1.5
  - 1.0
lstm_layers: 1
max_epochs: 10
num_workers: 1
precision: 16-mixed
resume_ckpt: checkpoints/last.ckpt
val_days: 14
val_mode: ratio
val_ratio: 0.2
warm_start_ckpt: checkpoints/best.ckpt
