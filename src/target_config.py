# process_period_targets.py
from __future__ import annotations
import warnings
from typing import Dict
import numpy as np
import pandas as pd
from scipy.stats import skew
from sklearn.neighbors import LocalOutlierFactor

PERIOD_CONFIG: Dict[str, Dict] = {
    "1h": {"rolling_window": 96, "ewma": True, "lof_neighbors": 96, "annual_factor": (24*365) ** 0.5, "vj_W": 24, "vj_L": 96, "vj_tau": 1.6, "brk_N": 96, "brk_eps": 0.0015, "brk_vol": 1.2},
    "4h": {"rolling_window": 56, "ewma": True, "lof_neighbors": 48,  "annual_factor": (6*365) ** 0.5,  "vj_W": 12, "vj_L": 48, "vj_tau": 1.5, "brk_N": 48,  "brk_eps": 0.0015, "brk_vol": 1.2},
    "1d": {"rolling_window": 30, "ewma": True, "lof_neighbors": 30,  "annual_factor": (365) ** 0.5,     "vj_W": 7,  "vj_L": 30, "vj_tau": 1.4, "brk_N": 30,  "brk_eps": 0.001,  "brk_vol": 1.1},
}

def process_period_targets(df: pd.DataFrame, period: str, future_col: str, symbol_name: str | None = None) -> pd.DataFrame:
    assert period in PERIOD_CONFIG, f"Unknown period: {period}"
    cfg = PERIOD_CONFIG[period]

    feature_flags = {
        # åŸºç¡€ç›®æ ‡
        "target_logreturn": True,
        "target_binarytrend": True,
        "target_logsharpe": True,  # è¿™é‡Œä½œä¸ºâ€œç‰¹å¾â€ç”Ÿæˆ logsharpe_ratioï¼Œè‹¥éœ€è¦å¯å¤åˆ¶ä¸º target
        # æ³¢åŠ¨ç‡ & ç»“æ„
        "rolling_volatility": True,
        "parkinson_volatility": True,
        "ewma_volatility": cfg["ewma"],
        "return_skewness": True,
        "tail_bias": True,
        "amplitude_range": True,
        "atr_slope": True,
        # LOF
        "lof_detection": False,
        # å¤åˆç›®æ ‡
        "target_multiagree": True,
        "target_trend_persistence": True,
        "target_pullback_prob": True,
        "target_sideway_detect": True,
        "target_breakout_count": True,
        "target_max_drawdown": True,
        "target_drawdown_prob": True,
        # æ–°å¢ 4 ä¸ªç¼ºå¤±ç›®æ ‡
        "target_fundflow_strength": True,
        "target_vol_jump_prob": True,
        "target_realized_vol": True,
        "target_breakout_prob": True,
    }

    df = df.copy()
    df["_orig_idx"] = df.index
    df["_orig_ts"] = df["timestamp"]
    df = compute_targets(df, period, future_col, feature_flags)
    n_before = len(df)
    
    # ğŸ”§ ä¿®å¤ï¼šæ™ºèƒ½NaNæ¸…ç† - åªåˆ é™¤å…³é”®ç›®æ ‡åˆ—NaNçš„è¡Œï¼Œå¿½ç•¥å ä½ç¬¦ç›®æ ‡
    essential_targets = [
        "target_logreturn", "target_binarytrend", "target_logsharpe_ratio",
        "target_vol_jump_prob", "target_realized_vol", "target_breakout_prob"
    ]
    # åªæ£€æŸ¥å­˜åœ¨ä¸”ä¸æ˜¯å…¨NaNå ä½ç¬¦çš„ç›®æ ‡åˆ—
    critical_cols = [col for col in essential_targets if col in df.columns and not df[col].isna().all()]
    
    if critical_cols:
        # åªåˆ é™¤å…³é”®ç›®æ ‡åˆ—æœ‰NaNçš„è¡Œ
        df = df.dropna(subset=critical_cols).reset_index(drop=True)
    else:
        # å¦‚æœæ²¡æœ‰å…³é”®ç›®æ ‡åˆ—ï¼Œè‡³å°‘ç¡®ä¿æœ‰åŸºç¡€æ•°æ®
        df = df.dropna(subset=["close", "open", "high", "low"], how="all").reset_index(drop=True)
    
    n_after = len(df)
    print(f"[âœ…] {period} | rows: {n_before} â†’ {n_after} (drop {n_before-n_after})")
    return df

def compute_targets(df: pd.DataFrame, period: str, future_col: str, flags: Dict[str, bool]) -> pd.DataFrame:
    warnings.filterwarnings("ignore")
    eps = 1e-6
    close = "close"

    # === åŸºç¡€ ===
    # !! å…³é”®ä¿®å¤ï¼šåŒºåˆ†å†å²æ”¶ç›Šç‡ï¼ˆç”¨äºç‰¹å¾ï¼‰å’Œæœªæ¥æ”¶ç›Šç‡ï¼ˆç”¨äºç›®æ ‡ï¼‰ !!
    # å†å²æ”¶ç›Šç‡ (t-1 -> t)ï¼Œç”¨äºè®¡ç®—è¾“å…¥ç‰¹å¾ï¼Œä¸å«æœªæ¥ä¿¡æ¯
    df["past_logreturn"] = np.log(df[close] / df[close].shift(1))
    
    # æœªæ¥æ”¶ç›Šç‡ (t -> t+1)ï¼Œä»…ç”¨äºè®¡ç®—ç›®æ ‡ï¼ŒåŒ…å«æœªæ¥ä¿¡æ¯
    df["future_logreturn"] = np.log(df[future_col] / df[close])
    df["binary_trend"] = (df["future_logreturn"] > 0).astype(int)
    win = PERIOD_CONFIG[period]["rolling_window"]

    # === æ³¢åŠ¨ç‡ (ä½¿ç”¨ past_logreturn) ===
    if flags["rolling_volatility"]:
        df["rolling_volatility"] = np.log1p(df["past_logreturn"].rolling(win).std().fillna(0))
    if flags["parkinson_volatility"]:
        df["parkinson_volatility"] = np.log1p(((np.log(df["high"] / df["low"])) ** 2).rolling(win).mean().fillna(0))
    if flags["ewma_volatility"]:
        df["ewmavolatility"] = df["past_logreturn"].ewm(span=max(2, win // 2), adjust=False).std().fillna(0)

    # === logSharpe: ä½œä¸ºâ€œç‰¹å¾â€ (ä½¿ç”¨ä¿®æ­£åçš„æ³¢åŠ¨ç‡) ===
    if flags["target_logsharpe"]:
        vol = df.get("rolling_volatility", 1.0)
        df["target_logsharpe_ratio"] = df["future_logreturn"] / (vol + eps)
        # å¦‚éœ€ targetï¼Œä¹Ÿå¯ä»¥ï¼š
        # df["target_logsharpe_ratio"] = df["logsharpe_ratio"]

    # === ç»“æ„ (ä½¿ç”¨ past_logreturn) ===
    if flags["return_skewness"]:
        df["return_skewness"] = df["past_logreturn"].rolling(win).apply(lambda x: skew(x.dropna()), raw=False)
    if flags["tail_bias"]:
        # é«˜ä½å½±çº¿å·® / ATR
        df["tail_bias_norm"] = ((df["high"] - df[close]) - (df[close] - df["low"])) / (df["atr"] + eps)
    if flags["amplitude_range"]:
        df["amplitude_range"] = df["high"] - df["low"]
    if flags["atr_slope"]:
        df["atr_slope"] = df["atr"].diff()

    # === LOF ä¸€æ¬¡æ€§æ‰¹é‡ï¼ˆå…¨æ˜¯â€œç‰¹å¾â€ï¼Œä¸å« targetï¼‰ ===
    if flags["lof_detection"]:
        lof_cols = [c for c in [
            "logreturn", "rolling_volatility", "parkinson_volatility", "ewmavolatility",
            "return_skewness", "tail_bias_norm", "amplitude_range", "atr_slope",
        ] if c in df.columns and df[c].notna().all()]
        if lof_cols:
            neigh = min(max(PERIOD_CONFIG[period]["lof_neighbors"], int(len(df) * 0.1)), 50)
            lof = LocalOutlierFactor(n_neighbors=neigh, contamination=0.02)
            X = df[lof_cols].replace([np.inf, -np.inf], np.nan).fillna(0.0)
            scores = lof.fit_predict(X)
            df["lof_score_all"] = lof.negative_outlier_factor_
            df["is_outlier_all"] = (scores == -1).astype(int)

    # === ç›®æ ‡å­—æ®µ (ä½¿ç”¨ future_logreturn) ===
    if flags["target_logreturn"]:
        # åˆ†ä½ç»Ÿè®¡ä½¿ç”¨å†å²ï¼Œé¿å…æ³„éœ²
        p = df["past_logreturn"].rolling(win)
        p10, p90 = p.quantile(0.10), p.quantile(0.90)
        df["target_logreturn"] = df["future_logreturn"]
        df["target_return_outlier_lower_10"] = (df["future_logreturn"] < p10).astype(int)
        df["target_return_outlier_upper_90"] = (df["future_logreturn"] > p90).astype(int)
        df["logreturn_pct_rank"] = p.apply(lambda x: x.rank(pct=True).iloc[-1] if len(x) else np.nan, raw=False)

    if flags["target_binarytrend"]:
        df["target_binarytrend"] = df["binary_trend"]

    if flags["target_max_drawdown"] or flags["target_drawdown_prob"]:
        cum_ret = df["future_logreturn"].cumsum()
        roll_max = cum_ret.rolling(win, min_periods=1).max()
        dd = cum_ret - roll_max
        if flags["target_max_drawdown"]:
            df["target_max_drawdown"] = dd
        if flags["target_drawdown_prob"]:
            df["target_drawdown_prob"] = (dd < 0).astype(int)

    if flags["target_trend_persistence"]:
        # è¿ç»­æ–¹å‘é•¿åº¦ï¼ˆæ›´ç¨³ï¼‰
        dir_ = np.sign(df["future_logreturn"].fillna(0))
        same_dir = dir_.shift(1).fillna(0) == dir_
        run = (~same_dir).cumsum()
        df["target_trend_persistence"] = same_dir.groupby(run).cumsum() + 1

    if flags["target_pullback_prob"]:
        # æ–¹å‘åè½¬ä¸”ä¹‹å‰ä¿æŒåŒå‘ â†’ å›è°ƒ
        dir_ = df["binary_trend"]
        rev = (dir_.shift(1) != dir_) & (dir_.shift(2) == dir_)
        df["target_pullback_prob"] = rev.astype(int)

    if flags["target_sideway_detect"]:
        # é˜ˆå€¼å…ˆä¿ç•™å¸¸é‡ï¼Œåç»­å¯æ¢æˆåˆ†ä½é˜ˆå€¼
        low_vol = df["rolling_volatility"].rolling(max(2, win // 2)).mean() < 0.02
        neutral = df["future_logreturn"].abs() < 0.001
        df["target_sideway_detect"] = (low_vol & neutral).astype(int)

    if flags["target_breakout_count"]:
        up_seq = df["future_logreturn"] > 0
        df["target_breakout_count"] = up_seq.groupby((~up_seq).cumsum()).cumsum()

    # === æ–°å¢ç›®æ ‡ï¼šfundflow_strengthï¼ˆå›å½’ï¼‰ ===
    if flags.get("target_fundflow_strength", False):
        # æ£€æŸ¥å¿…éœ€åˆ—æ˜¯å¦å­˜åœ¨ï¼Œè‹¥ä¸å­˜åœ¨åˆ™è·³è¿‡ç”Ÿæˆæ­¤ç›®æ ‡
        required_cols = ["exch_netflow", "stablecoin_mcap", "etf_flow", "cb_premium"]
        missing_cols = [c for c in required_cols if c not in df.columns]
        
        if missing_cols:
            print(f"âš ï¸ è·³è¿‡ target_fundflow_strengthï¼šç¼ºå°‘åŸºç¡€æ•°æ®åˆ— {missing_cols}")
            # ä¸åˆ›å»ºå ä½ç¬¦åˆ—ï¼Œé¿å…å½±å“æ•°æ®æ¸…ç†è¿‡ç¨‹
            pass
        else:
            # éœ€è¦ä»¥ä¸‹åˆ—ï¼ˆå·²åœ¨èåˆé˜¶æ®µ shift/ffillï¼Œå¹¶å¯èƒ½åšè¿‡æ ‡å‡†åŒ–ï¼‰ï¼š
            # exch_netflow(å–å‹å–è´Ÿ)ã€stablecoin_mcap(å¢é‡)ã€etf_flowã€cb_premium
            w_ex, w_st, w_etf, w_cb = 0.35, 0.25, 0.25, 0.15
            ex = df.get("exch_netflow")
            st = df.get("stablecoin_mcap")
            et = df.get("etf_flow")
            cb = df.get("cb_premium")
            # å·®åˆ†/æ ‡å‡†åŒ–ï¼ˆé²æ£’ï¼‰ï¼š
            def _z(x: pd.Series):
                if x is None: return None
                xm = x.astype(float)
                mu = xm.mean(); sd = xm.std(ddof=0)
                sd = sd if sd and sd > 1e-6 else 1.0
                return (xm - mu) / sd
            ex_z = -_z(ex) if ex is not None else 0.0   # å‡€æµå‡ºä¸ºæ­£å–å‹ â†’ å–è´Ÿ
            st_d = st.diff() if st is not None else None
            st_z = _z(st_d) if st_d is not None else 0.0
            et_z = _z(et) if et is not None else 0.0
            cb_z = _z(cb) if cb is not None else 0.0
            df["target_fundflow_strength"] = (
                w_ex * (ex_z if isinstance(ex_z, pd.Series) else 0.0) +
                w_st * (st_z if isinstance(st_z, pd.Series) else 0.0) +
                w_etf * (et_z if isinstance(et_z, pd.Series) else 0.0) +
                w_cb * (cb_z if isinstance(cb_z, pd.Series) else 0.0)
            )

    # === æ–°å¢ç›®æ ‡ï¼švol_jump_probï¼ˆåˆ†ç±»ï¼‰ ===
    if flags.get("target_vol_jump_prob", False):
        W = PERIOD_CONFIG[period]["vj_W"]; L = PERIOD_CONFIG[period]["vj_L"]; tau = PERIOD_CONFIG[period]["vj_tau"]
        hist_vol = df["rolling_volatility"].rolling(L).mean()
        fut = df["future_logreturn"].shift(-1).rolling(W).std()
        ratio = (fut / (hist_vol + 1e-6)).fillna(0.0)
        df["target_vol_jump_prob"] = (ratio >= tau).astype(int)

    # === æ–°å¢ç›®æ ‡ï¼šrealized_volï¼ˆå›å½’ï¼‰ ===
    if flags.get("target_realized_vol", False):
        ann = PERIOD_CONFIG[period]["annual_factor"]
        # æœªæ¥ W çª—çš„å®ç°æ³¢åŠ¨ï¼ˆå¹´åŒ–ï¼‰ï¼š
        W = PERIOD_CONFIG[period]["vj_W"]
        rv = df["future_logreturn"].shift(-1).rolling(W).apply(lambda x: float(np.sqrt(np.sum(np.square(x.astype(float))) + 1e-12)), raw=False)
        df["target_realized_vol"] = rv * ann

    # === æ–°å¢ç›®æ ‡ï¼šbreakout_probï¼ˆåˆ†ç±»ï¼‰ ===
    if flags.get("target_breakout_prob", False):
        N = PERIOD_CONFIG[period]["brk_N"]; eps = PERIOD_CONFIG[period]["brk_eps"]; vthr = PERIOD_CONFIG[period]["brk_vol"]
        # ç®€åŒ–å£å¾„ï¼šè¿‘ N çª—çš„å±€éƒ¨é«˜ä½ + é‡èƒ½ç¡®è®¤
        hi = df["high"].rolling(N, min_periods=2).max(); lo = df["low"].rolling(N, min_periods=2).min()
        vol = df.get("volume", pd.Series(np.nan, index=df.index)).astype(float)
        v_mean = vol.rolling(max(2, N//4)).mean(); v_ok = (vol / (v_mean + 1e-6)) >= vthr
        up_brk = (df["close"].shift(-1) >= (hi * (1.0 + eps))) & v_ok
        dn_brk = (df["close"].shift(-1) <= (lo * (1.0 - eps))) & v_ok
        df["target_breakout_prob"] = (up_brk | dn_brk).astype(int)

    # æ¸…ç†ä¸´æ—¶åˆ—
    df.drop(columns=["logreturn", "binary_trend", "past_logreturn", "future_logreturn"], inplace=True, errors="ignore")
    
    # ğŸ”§ å¥å£®æ€§æ£€æŸ¥ï¼šæŠ¥å‘Šç”Ÿæˆç›®æ ‡çš„ç»Ÿè®¡ä¿¡æ¯
    target_cols = [c for c in df.columns if c.startswith("target_")]
    if target_cols:
        print(f"\nğŸ“Š ç›®æ ‡ç”Ÿæˆç»Ÿè®¡ ({period}):")
        for col in target_cols:
            if col in df.columns:
                valid_count = df[col].notna().sum()
                total_count = len(df)
                valid_pct = valid_count / total_count if total_count > 0 else 0
                print(f"  {col}: {valid_count}/{total_count} ({valid_pct:.1%}) æœ‰æ•ˆå€¼")
                if valid_pct < 0.1:  # æœ‰æ•ˆå€¼å°‘äº10%
                    print(f"    âš ï¸ è­¦å‘Šï¼š{col} æœ‰æ•ˆå€¼è¿‡å°‘ï¼Œå¯èƒ½å½±å“è®­ç»ƒæ•ˆæœ")
    
    return df
