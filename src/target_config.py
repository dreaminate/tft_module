# target_config.py
"""
ç›®æ ‡æž„é€ æ¨¡å—: compute_targets()
ç”¨äºŽä¸ºæ¯ä¸ªå‘¨æœŸ ( 1h / 4h / 1d )åŠ å¯†è´§å¸æ•°æ®æž„é€ è®­ç»ƒç›®æ ‡å­—æ®µ ( target_ )å’Œè¾…åŠ©ç‰¹å¾ ( éž target_ )ã€‚
âœ… åˆ†ç±»ç›®æ ‡: 
    - target_binarytrend: ä¸Šæ¶¨ä¸º 1, éžä¸Šæ¶¨ä¸º 0
    - target_multiagree: å¤šå‘¨æœŸä¸€è‡´æ–¹å‘ ( 1 or 0 )
    - target_pullback_prob: æ¶¨ä¸­è·Œã€è·Œä¸­æ¶¨çš„çŸ­æœŸå›žè°ƒä¿¡å·
    - target_sideway_detect: å½“å‰æ˜¯å¦ä¸ºéœ‡è¡åŒºé—´ ( ä½Žæ³¢åŠ¨ + ä¸­æ€§æ¶¨å¹… )
    - target_return_outlier_upper_75: logreturn æ˜¯å¦å±žäºŽ P75 ä¸Šåˆ†ä½
    - target_return_outlier_upper_90: logreturn æ˜¯å¦å±žäºŽ P90 ä¸Šåˆ†ä½
    - target_return_outlier_lower_25: logreturn æ˜¯å¦å±žäºŽ P25 ä¸‹åˆ†ä½
    - target_return_outlier_lower_10: logreturn æ˜¯å¦å±žäºŽ P10 ä¸‹åˆ†ä½
    - target_trend3class: è¶‹åŠ¿ä¸‰åˆ†ç±» ( ä¸Šæ¶¨ = 2 / ä¸‹è·Œ = 0 / æ¨ªç›˜ = 1 )

âœ… å›žå½’ç›®æ ‡: 
    - target_logreturn: log(future / close)ï¼Œå¯¹æ•°æ”¶ç›ŠçŽ‡
    - target_logsharpe_ratio: logreturn / volatility, é£Žé™©è°ƒæ•´æ”¶ç›Š
    - target_trend_persistence: å½“å‰è¶‹åŠ¿æŒç»­æ­¥æ•° ( å¦‚è¿žç»­ä¸Šæ¶¨ )
    - target_fundflow_strength: é“¾ä¸Šèµ„é‡‘æµ ( å½“å‰ç•™ç©º )
    - target_breakout_count: è¿‘æœŸè¿žç»­ä¸Šæ¶¨æˆ–çªç ´æ¬¡æ•°
    - target_max_drawdown: åŽ†å²å›žæ’¤æœ€å¤§å€¼ ( è¿‘ N æ­¥ )
    - target_drawdown_prob: æ˜¯å¦å¤„äºŽå›žæ’¤çŠ¶æ€ ( è¿‘ N æ­¥æ”¶ç›Šä¸ºè´Ÿ )

âœ… æ³¢åŠ¨çŽ‡ / è¾…åŠ©æŒ‡æ ‡ ( éž target ): 
    - rolling_volatility: log(1+std(logreturn))
    - parkinson_volatility: åŸºäºŽé«˜ä½Žä»·çš„æ³¢åŠ¨çŽ‡ä¼°è®¡
    - ewma_volatility: æŒ‡æ•°åŠ æƒæ³¢åŠ¨çŽ‡
    - aparch_volatility / egarch_volatility: ARCHæ—æ³¢åŠ¨çŽ‡ä¼°è®¡
    - vol_skewness: æ³¢åŠ¨çŽ‡ååº¦
    - return_skewness: æ”¶ç›ŠçŽ‡ååº¦
    - tail_bias: Kçº¿å°¾éƒ¨ååº¦
    - amplitude_range: æŒ¯å¹… ( high - low )
    - atr_slope: ATR çš„æ–œçŽ‡ï¼Œè¶‹åŠ¿å¼ºå¼±
    - LOF å¼‚å¸¸åˆ†æ•° + å¼‚å¸¸æ ‡ç­¾ ( æ¯ä¸ªå­—æ®µ )

å‚æ•°è¯´æ˜Ž: 
    - df: å¸¦æœ‰ OHLCV + future_close çš„ DataFrame
    - period: æ—¶é—´å‘¨æœŸï¼Œå¦‚ "1h"
    - future_col: æœªæ¥ä»·æ ¼åˆ—å ( ä¸€èˆ¬ä¸º "future_close" )
    - symbol_name: å¦‚ "BTC_USDT"
    - feature_flags: æŽ§åˆ¶å­—æ®µæž„é€ å¼€å…³çš„å­—å…¸
"""

import warnings
from arch import arch_model
from scipy.stats import skew
from sklearn.neighbors import LocalOutlierFactor
import numpy as np
import pandas as pd
from datetime import datetime

# === 1ï¸âƒ£ å‘¨æœŸé…ç½®å­—å…¸ ===
PERIOD_CONFIG = {
    "1h":  {"rolling_window": 48, "garch": False, "ewma": True,  "lof_neighbors": 96},
    "4h":  {"rolling_window": 48, "garch": False, "ewma": True,  "lof_neighbors": 48},
    "1d":  {"rolling_window": 30, "garch": False, "ewma": True ,"lof_neighbors": 30}
}

# === 2ï¸âƒ£ åŒ…è£…å‡½æ•° ===



# å‘¨æœŸé…ç½®ç¤ºä¾‹ï¼ˆéœ€åœ¨ä¸»è„šæœ¬æˆ–é…ç½®æ–‡ä»¶ä¸­å®šä¹‰ï¼‰

def process_period_targets(df: pd.DataFrame, period: str, future_col: str, symbol_name: str = None):
    """
    æ‰§è¡Œç›®æ ‡æž„é€ ã€æ¸…æ´— NaNï¼Œå¹¶æ‰“å°æ¸…æ´—ä¿¡æ¯ä¸Žåˆ é™¤åŒºé—´ã€‚
    """
    assert period in PERIOD_CONFIG, f"[âŒ] æœªçŸ¥å‘¨æœŸ: {period}"
    cfg = PERIOD_CONFIG[period]

    feature_flags = {
        "target_logreturn": True,
        "target_binarytrend": True,
        "target_logsharpe": True,
        "rolling_volatility": True,
        "parkinson_volatility": True,
        "logsharpe_ratio": True,
        "ewma_volatility": cfg["ewma"],
        "garch_volatility": cfg["garch"],
        "vol_skewness": cfg["garch"],
        "return_skewness": True,
        "tail_bias": True,
        "amplitude_range": True,
        "atr_slope": True,
        "lof_detection": True,
        "fundflow_strength": False,
        "target_multiagree": True,
        "target_trend_persistence": True,
        "target_pullback_prob": True,
        "target_sideway_detect": True,
        "target_breakout_count": True,
        "target_max_drawdown": True,
        "target_drawdown_prob": True,
        "target_trend3class": True
    }

    df = df.copy()
    n_before = len(df)

    # è®°å½•åŽŸå§‹ç´¢å¼•å’Œæ—¶é—´
    df["_original_index"] = df.index
    df["_original_timestamp"] = df["timestamp"]

    # === æž„é€ ç›®æ ‡å­—æ®µ ===
    df = compute_targets(df, period=period, future_col=future_col, feature_flags=feature_flags)

    # æ‰¾å‡º NaN è¡Œ
    nan_rows = df[df.isna().any(axis=1)]
    # === æ‰“å° NaN è¡Œè¯¦ç»†ä¿¡æ¯ ===w
    if not nan_rows.empty:
        print(f"[âš ï¸] å‘çŽ° NaN è¡Œï¼Œå…± {len(nan_rows)} è¡Œ:")
        print(nan_rows.head())  # æ‰“å° NaN è¡Œçš„å‰å‡ è¡Œè¿›è¡Œè¯¦ç»†æŸ¥çœ‹
    # åˆ é™¤ NaN è¡Œ
    df_cleaned = df.dropna(how="any").reset_index(drop=True)
    n_after = len(df_cleaned)

    print(f"[âœ…] å‘¨æœŸ: {period} | åŽŸå§‹è¡Œæ•°: {n_before} â†’ æ¸…æ´—åŽ: {n_after} | åˆ é™¤è¡Œæ•°: {n_before - n_after}")

    # === æ‰“å°åˆ é™¤åŒºé—´åˆ†æž ===
    if not nan_rows.empty:
        deleted_indices = nan_rows["_original_index"].values
        deleted_timestamps = nan_rows["_original_timestamp"].values

        is_continuous = (max(deleted_indices) - min(deleted_indices) + 1) == len(deleted_indices)

        if is_continuous:
            start_ts = int(deleted_timestamps[0])
            end_ts = int(deleted_timestamps[-1])
            start_dt = datetime.utcfromtimestamp(start_ts / 1000)
            end_dt = datetime.utcfromtimestamp(end_ts / 1000)
            print(f"[ðŸ§¹] åˆ é™¤è¡Œä¸ºè¿žç»­: æ—¶é—´èŒƒå›´ {start_dt} ~ {end_dt}")
        else:
            print(f"[ðŸ§¹] åˆ é™¤è¡Œä¸ºç¦»æ•£ï¼Œå…± {len(deleted_indices)} è¡Œï¼Œå‰ 10 è¡Œæ—¶é—´ç‚¹ï¼š")
            for ts in deleted_timestamps[:10]:
                dt_str = datetime.utcfromtimestamp(int(ts) / 1000)
                print(f"   â€¢ {dt_str}")

    return df_cleaned


def compute_targets(df, period, future_col,feature_flags=None):
    warnings.filterwarnings("ignore")
    epsilon = 1e-6
    close_col = "close"

    if feature_flags is None:
        feature_flags = {
            "target_logreturn": True,
            "target_binarytrend": True,
            "target_logsharpe": True,
            "rolling_volatility": True,
            "parkinson_volatility": True,
            "logsharpe_ratio": True,
            "ewma_volatility": True,
            "return_skewness": True,
            "tail_bias": True,
            "amplitude_range": True,
            "atr_slope": True,
            "lof_detection": True,
            "fundflow_strength": False,
            "target_multiagree": True,
            "target_trend_persistence": True,
            "target_pullback_prob": True,
            "target_sideway_detect": True,
            "target_breakout_count": True,
            "target_max_drawdown": True,
            "target_drawdown_prob": True,
            "target_trend3class": True
        }
           

    df["logreturn"] = np.log(df[future_col] / df[close_col])
    df["binary_trend"] = (df["logreturn"] > 0).astype(int)

    
    if feature_flags["rolling_volatility"]:
        df["rolling_volatility"] = np.log1p(df["logreturn"].rolling(48).std().fillna(0))

    if feature_flags["parkinson_volatility"]:
        df["parkinson_volatility"] = np.log1p(((np.log(df["high"] / df["low"])) ** 2).rolling(48).mean().fillna(0))

    if feature_flags["logsharpe_ratio"]:
        df["logsharpe_ratio"] = df["logreturn"] / (df.get("rolling_volatility", 1.0) + epsilon)

    if feature_flags["ewma_volatility"] and period in ["1h", "4h","1d"]:
        print(f"[ðŸŒ€] æ­£åœ¨è®¡ç®— ewma_volatility - {period}")
        df["ewmavolatility"] = df["logreturn"].ewm(span=24, adjust=False).std().fillna(0)

   

    if feature_flags["return_skewness"]:
        df["return_skewness"] = df["logreturn"].rolling(7).apply(lambda x: skew(x.dropna()), raw=False)

    if feature_flags["tail_bias"]:
        df["tail_bias"] = (df["high"] - df["close"]) - (df["close"] - df["low"])

    if feature_flags["amplitude_range"]:
        df["amplitude_range"] = df["high"] - df["low"]

    if feature_flags["atr_slope"]:
        df["atr_slope"] = df["atr"].diff()

    if feature_flags["lof_detection"]:
        lof_fields = [
            "logreturn", 
            "rolling_volatility", "parkinson_volatility",
            "logsharpe_ratio", "return_skewness", "vol_skewness",
            "tail_bias", "amplitude_range", "atr_slope"
                    ]

        if feature_flags["ewma_volatility"] and period in ["1h", "4h", "1d"]:
            lof_fields.append("ewmavolatility")

        available = [col for col in lof_fields if col in df.columns and df[col].isna().sum() == 0]
        if available:
            default_n_neighbors = {"1h": 96, "4h": 48, "1d": 30}[period]
            for feat in available:
                feat_data = df[[feat]].dropna()
                if len(feat_data) < default_n_neighbors + 1:
                    continue
                dynamic_neighbors = min(max(default_n_neighbors, int(len(feat_data) * 0.1)), 50)
                try:
                    lof = LocalOutlierFactor(n_neighbors=dynamic_neighbors, contamination=0.02)
                    scores = lof.fit_predict(feat_data)
                    df.loc[feat_data.index, f"lof_score_{feat}"] = lof.negative_outlier_factor_
                    df.loc[feat_data.index, f"is_outlier_{feat}"] = (scores == -1).astype(int)
                except Exception:
                    df[f"lof_score_{feat}"] = np.nan
                    df[f"is_outlier_{feat}"] = 0

    # ç›®æ ‡æž„é€ 
    if feature_flags["target_logreturn"]:
        df["target_logreturn"] = df["logreturn"]
    if feature_flags.get("target_logreturn"):
        rolling_window_q = {"1h": 96, "4h": 48, "1d": 30}.get(period, 96)
        p25 = df["logreturn"].rolling(rolling_window_q).quantile(0.25)
        p75 = df["logreturn"].rolling(rolling_window_q).quantile(0.75)
        p10 = df["logreturn"].rolling(rolling_window_q).quantile(0.10)
        p90 = df["logreturn"].rolling(rolling_window_q).quantile(0.90)

        df["target_return_outlier_upper_75"] = (df["logreturn"] > p75).astype(int)
        df["target_return_outlier_upper_90"] = (df["logreturn"] > p90).astype(int)
        df["target_return_outlier_lower_25"] = (df["logreturn"] < p25).astype(int)
        df["target_return_outlier_lower_10"] = (df["logreturn"] < p10).astype(int)
        df["logreturn_pct_rank"] = (
        df["logreturn"].rolling(rolling_window_q)
        .apply(lambda x: x.rank(pct=True).iloc[-1], raw=False)
    )
    if feature_flags.get("target_logreturn"):
        rolling_window_q = {"1h": 96, "4h": 48, "1d": 30}.get(period, 96)
        p25 = df["logreturn"].rolling(rolling_window_q).quantile(0.25)
        p75 = df["logreturn"].rolling(rolling_window_q).quantile(0.75)
        p10 = df["logreturn"].rolling(rolling_window_q).quantile(0.10)
        p90 = df["logreturn"].rolling(rolling_window_q).quantile(0.90)

        df["target_return_outlier_upper_75"] = (df["logreturn"] > p75).astype(int)
        df["target_return_outlier_upper_90"] = (df["logreturn"] > p90).astype(int)
        df["target_return_outlier_lower_25"] = (df["logreturn"] < p25).astype(int)
        df["target_return_outlier_lower_10"] = (df["logreturn"] < p10).astype(int)
        df["logreturn_pct_rank"] = (
            df["logreturn"].rolling(rolling_window_q)
            .apply(lambda x: x.rank(pct=True).iloc[-1], raw=False)
        )

    
    

    if feature_flags.get("target_max_drawdown"):
        window_dd = {"1h": 96, "4h": 48, "1d": 30}.get(period, 96)
        cum_return = df["logreturn"].cumsum()
        rolling_max = cum_return.rolling(window_dd, min_periods=1).max()
        df["target_max_drawdown"] = (cum_return - rolling_max).fillna(0)

    if feature_flags.get("target_drawdown_prob"):
        window_dd = {"1h": 96, "4h": 48, "1d": 30}.get(period, 96)
        cum_return = df["logreturn"].cumsum()
        rolling_max = cum_return.rolling(window_dd, min_periods=1).max()
        df["target_drawdown_prob"] = (cum_return < rolling_max).astype(int)
        if feature_flags["target_binarytrend"]:
            df["target_binarytrend"] = df["binary_trend"]

    if feature_flags["target_logsharpe"] and "logsharpe_ratio" in df:
        df["target_logsharpe_ratio"] = df["logsharpe_ratio"]

    if feature_flags["target_multiagree"]:
        df["target_multiagree"] = df["binary_trend"].rolling(3, min_periods=1).apply(lambda x: int(len(set(x)) == 1))

    if feature_flags["target_trend_persistence"]:
        persistence = (df["binary_trend"] == df["binary_trend"].shift()).astype(int)
        df["target_trend_persistence"] = persistence.groupby((persistence != 1).cumsum()).cumsum()

    if feature_flags["target_pullback_prob"]:
        direction = df["binary_trend"]
        reversal = (direction.shift(1) != direction) & (direction.shift(2) == direction)
        df["target_pullback_prob"] = reversal.astype(int)

    if feature_flags["target_sideway_detect"]:
        low_vol = df["rolling_volatility"].rolling(24).mean() < 0.02
        neutral_ret = df["logreturn"].abs() < 0.001
        df["target_sideway_detect"] = (low_vol & neutral_ret).astype(int)

    if feature_flags["fundflow_strength"]:
        df["fundflow_strength"] = np.nan  # placeholder for future on-chain data

    if feature_flags["target_breakout_count"]:
        up = df["logreturn"] > 0
        df["target_breakout_count"] = up.groupby((~up).cumsum()).cumsum()

    df.drop(columns=["logreturn"], inplace=True, errors="ignore")
    return df   

