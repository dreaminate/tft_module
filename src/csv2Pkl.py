"""Convert fused CSV (full or slim) to Pickle, aligned with expert folder layout.

Usage:
  python src/csv2Pkl.py --config configs/fuse_fundamentals.yaml --which full
  python src/csv2Pkl.py --config configs/fuse_fundamentals.yaml --which slim
"""

from pathlib import Path
import argparse
import pandas as pd
from typing import Any, Dict, Optional


def _load_yaml(path: str) -> Dict[str, Any]:
    # è½»é‡ YAML è§£æžï¼ˆä¸Ž fuse ä¸­ä¸€è‡´çš„é™çº§ç‰ˆï¼‰
    try:
        import yaml  # type: ignore
        with open(path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f.read()) or {}
    except Exception:
        pass
    text = Path(path).read_text(encoding='utf-8')
    def _parse_value(v: str):
        vs = v.strip()
        if vs.lower() in ("true","yes","on"): return True
        if vs.lower() in ("false","no","off"): return False
        if vs.lower() in ("null","none","~"): return None
        if (vs.startswith('"') and vs.endswith('"')) or (vs.startswith("'") and vs.endswith("'")):
            return vs[1:-1]
        try:
            if vs.isdigit() or (vs.startswith('-') and vs[1:].isdigit()):
                return int(vs)
            return float(vs)
        except Exception:
            return vs
    root: Dict[str, Any] = {}
    stack: list[tuple[int, Dict[str, Any]]] = [(-1, root)]
    for raw in text.splitlines():
        if not raw.strip():
            continue
        line = raw.split('#',1)[0]
        if not line.strip():
            continue
        indent = len(line) - len(line.lstrip(' '))
        line = line.strip()
        if ':' not in line:
            continue
        key, rest = line.split(':',1)
        key = key.strip(); rest = rest.strip()
        while stack and stack[-1][0] >= indent:
            stack.pop()
        parent = stack[-1][1] if stack else root
        if rest == '':
            d: Dict[str, Any] = {}
            parent[key] = d
            stack.append((indent, d))
        else:
            parent[key] = _parse_value(rest)
    return root


def _compose_paths(cfg: Dict[str, Any], which: str) -> tuple[Path, Path]:
    # å¤åˆ» fuse çš„è·¯å¾„æŽ¨å¯¼ï¼šæ–‡ä»¶ååŽç¼€ + åˆ†ç»„æ–‡ä»¶å¤¹
    extra = cfg.get('extra_field') or {}
    out_csv = cfg.get('out_csv', 'data/merged/full_merged_with_fundamentals.csv')
    slim_csv = cfg.get('slim_csv', 'data/merged/full_merged_slim.csv')
    path = Path(out_csv if which == 'full' else slim_csv)

    # suffix
    name = (extra.get('name') or '').strip()
    value = extra.get('value')
    how = str(extra.get('append_to_filename', 'name')).strip().lower()
    suffix = ''
    if name and how not in ('none', 'off', 'no', 'false'):
        if how == 'both' and value is not None:
            suffix = f'_{name}-{value}'
        elif how == 'value' and value is not None:
            suffix = f'_{value}'
        else:
            suffix = f'_{name}'
    if suffix:
        path = path.with_name(path.stem + suffix + path.suffix)

    # group folder
    if extra.get('group_to_folder'):
        mode = str(extra.get('folder_mode', how)).strip().lower()
        tag = ''
        if name:
            if mode == 'both' and value is not None:
                tag = f'{name}-{value}'
            elif mode == 'value' and value is not None:
                tag = f'{value}'
            else:
                tag = f'{name}'
        base_root = extra.get('folder_root')
        if base_root:
            path = Path(base_root) / tag / path.name
        elif tag:
            path = path.parent / tag / path.name

    # outputs next to CSV
    dst = path.with_suffix('.pkl')
    return path, dst


def convert_csv_to_pkl(src_file: Path, dst_file: Path, selected_periods: Optional[list[str]] = None):
    if not src_file.exists():
        print(f"[âŒ] æºæ–‡ä»¶ä¸å­˜åœ¨: {src_file}")
        return
    try:
        print(f"â–¶ è¯»å–: {src_file}")
        df = pd.read_csv(src_file)
        if 'timestamp' not in df.columns:
            print('âŒ ç¼ºå¤± timestamp å­—æ®µ'); return
        df['datetime'] = pd.to_datetime(df['timestamp'], unit='ms' if df['timestamp'].max() > 1e12 else None, errors='coerce')
        if selected_periods and 'period' in df.columns:
            before = len(df); df = df[df['period'].isin(selected_periods)]; print(f"ðŸ” å‘¨æœŸè¿‡æ»¤: {before} â†’ {len(df)}")
        if df.empty:
            print('âš ï¸ æ–‡ä»¶æ•°æ®ä¸ºç©ºï¼ˆè¿‡æ»¤åŽï¼‰'); return
        dst_file.parent.mkdir(parents=True, exist_ok=True)
        df.to_pickle(dst_file)
        print(f"âœ… ä¿å­˜ PKL â†’ {dst_file}")
    except Exception as e:
        print(f"âŒ è½¬æ¢å¤±è´¥: {e}")


if __name__ == '__main__':
    ap = argparse.ArgumentParser()
    ap.add_argument('--config', default='configs/fuse_fundamentals.yaml')
    ap.add_argument('--which', choices=['full','slim'], default='full', help='è½¬æ¢ full æˆ– slim è¾“å‡º')
    ap.add_argument('--periods', nargs='*', default=["1h","4h","1d"])
    args = ap.parse_args()

    cfg = _load_yaml(args.config)
    src, dst = _compose_paths(cfg, args.which)
    convert_csv_to_pkl(src, dst, args.periods)
    
    # ä¹Ÿé¡ºæ‰‹æç¤º slim/full å¦ä¸€ä¸ªæ–‡ä»¶ä½ç½®
    other = 'slim' if args.which == 'full' else 'full'
    try:
        o_src, o_dst = _compose_paths(cfg, other)
        print(f"â„¹ï¸ å¦å¤–ä¸€ä¸ªè¾“å‡º: {other}: {o_src} -> {o_dst.with_suffix('.pkl')}")
    except Exception:
        pass
